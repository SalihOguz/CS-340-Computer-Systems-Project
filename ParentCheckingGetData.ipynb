{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<img src=\"https://alanattableau.files.wordpress.com/2014/12/cropped-databender4.png\" align=center>\n",
    "<h1 align=center>The Last Databenders</h1>\n",
    "<h4 align=center>Sponsored By Gutenberg</h4>\n",
    "<img src=\"http://www.gutenberg.org/pics/logo-144x144.png\" align=center>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HEADER_MARKERS = [\n",
    "\n",
    "      '* START OF THE PROJECT GUTENBERG',\n",
    "      '* START OF THIS PROJECT GUTENBERG',\n",
    "      'This etext was prepared by',\n",
    "      'E-text prepared by',\n",
    "      'Produced by',\n",
    "      'Distributed Proofreading Team',\n",
    "      '*END THE SMALL PRINT',\n",
    "      '***START OF THE PROJECT GUTENBERG',\n",
    "      'This etext was produced by',\n",
    "      '* START OF THE COPYRIGHTED',\n",
    "      'The Project Gutenberg',\n",
    "      'http://gutenberg.spiegel.de/ erreichbar.',\n",
    "      'Project Runeberg publishes',\n",
    "      'Beginning of this Project Gutenberg',\n",
    "      'Project Gutenberg Online Distributed',\n",
    "      'Gutenberg Online Distributed',\n",
    "      'the Project Gutenberg Online Distributed',\n",
    "      'Project Gutenberg TEI',\n",
    "      'This eBook was prepared by',\n",
    "      'http://gutenberg2000.de erreichbar.',\n",
    "      'This Etext was prepared by',\n",
    "      'Gutenberg Distributed Proofreaders',\n",
    "      'the Project Gutenberg Online Distributed Proofreading Team',\n",
    "      '**The Project Gutenberg',\n",
    "      '*SMALL PRINT!',\n",
    "      'More information about this book is at the top of this file.',\n",
    "      'tells you about restrictions in how the file may be used.',\n",
    "      'of the etext through OCR.',\n",
    "      '**These eBooks Were Prepared By Thousands of Volunteers!**',\n",
    "      'SERVICE THAT CHARGES FOR DOWNLOAD',\n",
    "      'We need your donations more than ever!',\n",
    "      ' * START OF THIS PROJECT GUTENBERG',\n",
    "      '**     SMALL PRINT!'\n",
    "    \n",
    "]\n",
    "FOOTER_MARKERS = [\n",
    "    '* END OF THE PROJECT GUTENBERG',\n",
    "    '* END OF THIS PROJECT GUTENBERG',\n",
    "    '***END OF THE PROJECT GUTENBERG',\n",
    "    'End of the Project Gutenberg',\n",
    "    'End of The Project Gutenberg',\n",
    "    'by Project Gutenberg',\n",
    "    'End of Project Gutenberg',\n",
    "    'End of this Project Gutenberg',\n",
    "    '        ***END OF THE PROJECT GUTENBERG',\n",
    "    '* END OF THE COPYRIGHTED',\n",
    "    'End of this is COPYRIGHTED',\n",
    "    '*This is a COPYRIGHTED Project Gutenberg Etext, Details Above*',\n",
    "    'More information about this book is at the top of this file.',\n",
    "    'We need your donations more than ever!',\n",
    "    '<<THIS ELECTRONIC VERSION OF',\n",
    "    'END OF PROJECT GUTENBERG',\n",
    "    ' End of the Project Gutenberg',\n",
    "    ' * END OF THIS PROJECT GUTENBERG',\n",
    "    \"THE END\"  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Children\n",
      "DONEE\n"
     ]
    }
   ],
   "source": [
    "import urllib2, string, json  # the lib that handles the url stuff\n",
    "from bs4 import BeautifulSoup\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover\n",
    "from pyspark.sql import Row\n",
    "\n",
    "def ParseBook(data):\n",
    "    is_header = False\n",
    "    is_footer = False\n",
    "    for line in data:\n",
    "        for footer in FOOTER_MARKERS:\n",
    "            if footer in line.strip():\n",
    "                is_footer = True\n",
    "                break\n",
    "        if is_footer:\n",
    "            break\n",
    "        if is_header:\n",
    "            for i in line.split():\n",
    "                word = i.strip().lower().translate(None, string.punctuation)\n",
    "                tx.write(word+\" \")\n",
    "\n",
    "        for header in HEADER_MARKERS:\n",
    "            if header in line.strip():\n",
    "                is_header = True\n",
    "                break\n",
    "    \n",
    "    \"\"\"for line in data: # files are iterable\n",
    "        for i in line.split():\n",
    "            word = i.strip().lower().translate(None, string.punctuation)\n",
    "            tx.write(word+\" \")\"\"\"\n",
    "                \n",
    "def FillDict(index, cat):\n",
    "    tx.write(cat+\"\\t\")\n",
    "    try:\n",
    "        data = urllib2.urlopen(\"http://www.gutenberg.org/files/\"+str(index)+\"/\"+str(index)+\"-0.txt\") # it's a file like object and works just like a file\n",
    "        ParseBook(data)\n",
    "    except urllib2.HTTPError:\n",
    "        try:\n",
    "            data = urllib2.urlopen(\"http://www.gutenberg.org/files/\"+str(index)+\"/\"+str(index)+\".txt\") # it's a file like object and works just like a file\n",
    "            ParseBook(data)\n",
    "        except:\n",
    "            pass\n",
    "    tx.write(\"\\n\")\n",
    "    \n",
    "def FindBookIndex():\n",
    "    categorise = ['Children']\n",
    "    for cat in categorise:\n",
    "        book_index = 0\n",
    "        print cat\n",
    "        while book_index < 100:\n",
    "            try:\n",
    "                html_doc = urllib2.urlopen(\"http://www.gutenberg.org/ebooks/search/?start_index=\"+str(book_index)+\"&query=\"+cat+\"+l.english\").read()\n",
    "                soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "                lis = soup.find_all(\"li\",  { \"class\" : \"booklink\" })\n",
    "                for i in range(len(lis)):\n",
    "                    index = lis[i].a['href'].split(\"/\")[2]\n",
    "                    FillDict(index, cat)\n",
    "                book_index += 26\n",
    "            except urllib2.HTTPError:\n",
    "                break\n",
    "                \n",
    "tx = open(\"main_Children.txt\", \"w\")\n",
    "FindBookIndex()\n",
    "tx.close()\n",
    "print \"DONEE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 2.0",
   "language": "python",
   "name": "python2-spark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}